{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtzqK+mcum0l5wl3gciIGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthpranav2/ROP-Optimization/blob/main/Synthetic_drilling_params_inducer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "READ-ME\n",
        "\n",
        "Upload the file \"initial_well_logs.zip\" and then start running the project."
      ],
      "metadata": {
        "id": "QquXorFhRv6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process Training Wells (All except S1, S2, S3)"
      ],
      "metadata": {
        "id": "gIlX1oCuRrE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpqpJ7WBIknQ",
        "outputId": "249b26c3-d1a0-4398-e52c-56152f2a3980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Block 1: Processing Training Wells ---\n",
            "Cleaning up old folder: 'training_and_testing_wells'\n",
            "Created directory: training_and_testing_wells/training_wells\n",
            "Successfully opened 'initial_well_logs.zip'.\n",
            "  Processing TRAINING well: D4...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D4_usable.csv\n",
            "  Processing TRAINING well: D29...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D29_usable.csv\n",
            "  Processing TRAINING well: D15...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D15_usable.csv\n",
            "  Processing TRAINING well: D14...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D14_usable.csv\n",
            "  Processing TRAINING well: D5...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D5_usable.csv\n",
            "  Processing TRAINING well: D7...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D7_usable.csv\n",
            "  Processing TRAINING well: D16...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D16_usable.csv\n",
            "  Processing TRAINING well: D17...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D17_usable.csv\n",
            "  Processing TRAINING well: D2...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D2_usable.csv\n",
            "  Processing TRAINING well: D12...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D12_usable.csv\n",
            "  Processing TRAINING well: D3...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D3_usable.csv\n",
            "  Processing TRAINING well: D1...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D1_usable.csv\n",
            "  Processing TRAINING well: D10...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D10_usable.csv\n",
            "  Processing TRAINING well: D20...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D20_usable.csv\n",
            "  Processing TRAINING well: D21...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D21_usable.csv\n",
            "  Processing TRAINING well: D23...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D23_usable.csv\n",
            "  Processing TRAINING well: D27...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D27_usable.csv\n",
            "  Processing TRAINING well: D8...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D8_usable.csv\n",
            "  Processing TRAINING well: D19...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D19_usable.csv\n",
            "  Processing TRAINING well: D18...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D18_usable.csv\n",
            "  Processing TRAINING well: D24...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D24_usable.csv\n",
            "  Processing TRAINING well: D30...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D30_usable.csv\n",
            "  Processing TRAINING well: D9...\n",
            "    -> Saved to training_and_testing_wells/training_wells/D9_usable.csv\n",
            "  Processing TRAINING well: A2...\n",
            "    -> Saved to training_and_testing_wells/training_wells/A2_usable.csv\n",
            "  Processing TRAINING well: A3...\n",
            "    -> Saved to training_and_testing_wells/training_wells/A3_usable.csv\n",
            "  Processing TRAINING well: A4...\n",
            "    -> Saved to training_and_testing_wells/training_wells/A4_usable.csv\n",
            "  Processing TRAINING well: A5...\n",
            "    -> Saved to training_and_testing_wells/training_wells/A5_usable.csv\n",
            "\n",
            "--- Block 1 Complete ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_ZIP_NAME = 'initial_well_logs.zip'\n",
        "OUTPUT_FOLDER_NAME = 'training_and_testing_wells'\n",
        "TRAINING_PATH = os.path.join(OUTPUT_FOLDER_NAME, 'training_wells')\n",
        "TEST_WELLS = ['S1', 'S2', 'S3'] # Wells to EXCLUDE\n",
        "\n",
        "# Set a random seed for reproducible results\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Define the 'Training' processing function (V_SH + RHOB logic) ---\n",
        "def generate_synthetic_data_train(df):\n",
        "    num_rows = len(df)\n",
        "    if num_rows == 0: return None\n",
        "\n",
        "    # Check for required columns\n",
        "    if 'V_SH' not in df.columns or 'RHOB' not in df.columns:\n",
        "        print(f\"      -> ERROR: V_SH or RHOB missing. Cannot use this logic. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    # Handle potential missing values (e.g., fill with the mean)\n",
        "    df['V_SH'] = df['V_SH'].fillna(df['V_SH'].mean())\n",
        "    df['RHOB'] = df['RHOB'].fillna(df['RHOB'].mean())\n",
        "\n",
        "    strength_factor = (df['RHOB'] - df['RHOB'].min()) + (1 - df['V_SH'])\n",
        "    strength_factor_norm = (strength_factor - strength_factor.min()) / (strength_factor.max() - strength_factor.min())\n",
        "    df['synthetic_rock_strength'] = strength_factor_norm\n",
        "\n",
        "    # --- Generate Operator-Controlled Parameters (WOB, RPM) ---\n",
        "    wob_base = 20.0\n",
        "    wob_strength_effect = 30.0\n",
        "    wob_noise = np.random.normal(0, 4, num_rows)\n",
        "    wt_on_bit = wob_base + (df['synthetic_rock_strength'] * wob_strength_effect) + wob_noise\n",
        "    df['wt_on_bit'] = np.clip(wt_on_bit, 5, 70)\n",
        "\n",
        "    rpm_base = 160.0\n",
        "    rpm_strength_effect = -80.0\n",
        "    rpm_noise = np.random.normal(0, 10, num_rows)\n",
        "    surface_rpm = rpm_base + (df['synthetic_rock_strength'] * rpm_strength_effect) + rpm_noise\n",
        "    df['surface_rpm'] = np.clip(surface_rpm, 50, 220)\n",
        "\n",
        "    # --- Generate Resulting Parameter (ROP) ---\n",
        "    wob_norm = (df['wt_on_bit'] - df['wt_on_bit'].mean()) / df['wt_on_bit'].std()\n",
        "    rpm_norm = (df['surface_rpm'] - df['surface_rpm'].mean()) / df['surface_rpm'].std()\n",
        "\n",
        "    rop_base = 80.0\n",
        "    rop_wob_effect = 30.0\n",
        "    rop_rpm_effect = 25.0\n",
        "    rop_strength_effect = 50.0\n",
        "    rop_noise = np.random.normal(0, 15, num_rows)\n",
        "\n",
        "    rop_average = (\n",
        "        rop_base +\n",
        "        (rop_wob_effect * wob_norm) +\n",
        "        (rop_rpm_effect * rpm_norm) -\n",
        "        (rop_strength_effect * df['synthetic_rock_strength']) +\n",
        "        rop_noise\n",
        "    )\n",
        "\n",
        "    df['rop_avg'] = np.clip(rop_average, 5, 350)\n",
        "    return df\n",
        "\n",
        "# --- Main Script ---\n",
        "print(\"--- Starting Block 1: Processing Training Wells ---\")\n",
        "\n",
        "# Clean up old runs (if any)\n",
        "if os.path.exists(OUTPUT_FOLDER_NAME):\n",
        "    print(f\"Cleaning up old folder: '{OUTPUT_FOLDER_NAME}'\")\n",
        "    shutil.rmtree(OUTPUT_FOLDER_NAME)\n",
        "\n",
        "# Create the new directory structure\n",
        "os.makedirs(TRAINING_PATH, exist_ok=True)\n",
        "print(f\"Created directory: {TRAINING_PATH}\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(INPUT_ZIP_NAME, 'r') as zip_in:\n",
        "        print(f\"Successfully opened '{INPUT_ZIP_NAME}'.\")\n",
        "\n",
        "        for file_info in zip_in.infolist():\n",
        "            file_name = file_info.filename\n",
        "\n",
        "            # --- This is the key logic ---\n",
        "            # Get well key: e.g., \"initial_well_logs/A2.csv\" -> \"A2\"\n",
        "            well_key = os.path.splitext(os.path.basename(file_name))[0]\n",
        "\n",
        "            # Check if it's a CSV, not a junk file, AND not in our test list\n",
        "            if (file_name.endswith('.csv') and\n",
        "                not file_name.startswith('__') and\n",
        "                well_key not in TEST_WELLS and\n",
        "                well_key != 'initial_well_logs'): # Handle root folder case\n",
        "\n",
        "                print(f\"  Processing TRAINING well: {well_key}...\")\n",
        "\n",
        "                with zip_in.open(file_name) as f:\n",
        "                    df = pd.read_csv(io.TextIOWrapper(f, 'utf-8'))\n",
        "\n",
        "                df_processed = generate_synthetic_data_train(df)\n",
        "\n",
        "                if df_processed is not None:\n",
        "                    output_file_name = f\"{well_key}_usable.csv\"\n",
        "                    output_file_path = os.path.join(TRAINING_PATH, output_file_name)\n",
        "                    df_processed.to_csv(output_file_path, index=False)\n",
        "                    print(f\"    -> Saved to {output_file_path}\")\n",
        "                else:\n",
        "                    print(f\"    -> Skipped {well_key} (processing error or empty).\")\n",
        "\n",
        "    print(\"\\n--- Block 1 Complete ---\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR: '{INPUT_ZIP_NAME}' not found! Please upload it. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process S1, S2, S3 for \"Expected Results\""
      ],
      "metadata": {
        "id": "mzBG9HfQR7r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_ZIP_NAME = 'initial_well_logs.zip'\n",
        "OUTPUT_FOLDER_NAME = 'training_and_testing_wells'\n",
        "EXPECTED_PATH = os.path.join(OUTPUT_FOLDER_NAME, 'testing_wells', 'expected_result')\n",
        "TEST_WELLS = ['S1', 'S2', 'S3'] # Wells to INCLUDE\n",
        "\n",
        "# Set a random seed for reproducible results\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Define the 'Expected' processing function (GR + RHOB + ROP) ---\n",
        "def generate_synthetic_data_expected(df):\n",
        "    num_rows = len(df)\n",
        "    if num_rows == 0: return None\n",
        "\n",
        "    # Check for required columns\n",
        "    if 'GR' not in df.columns or 'RHOB' not in df.columns:\n",
        "        print(f\"      -> ERROR: GR or RHOB missing. Cannot use this logic. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    df['GR'] = df['GR'].fillna(df['GR'].mean())\n",
        "    df['RHOB'] = df['RHOB'].fillna(df['RHOB'].mean())\n",
        "    gr_norm = (df['GR'] - df['GR'].mean()) / df['GR'].std()\n",
        "    rhob_norm = (df['RHOB'] - df['RHOB'].mean()) / df['RHOB'].std()\n",
        "    strength_proxy = rhob_norm - gr_norm\n",
        "    df['synthetic_rock_strength'] = (strength_proxy - strength_proxy.min()) / (strength_proxy.max() - strength_proxy.min())\n",
        "\n",
        "    wob_base = 20.0\n",
        "    wob_strength_effect = 30.0\n",
        "    wob_noise = np.random.normal(0, 4, num_rows)\n",
        "    wt_on_bit = wob_base + (df['synthetic_rock_strength'] * wob_strength_effect) + wob_noise\n",
        "    df['wt_on_bit'] = np.clip(wt_on_bit, 5, 70)\n",
        "\n",
        "    rpm_base = 160.0\n",
        "    rpm_strength_effect = -80.0\n",
        "    rpm_noise = np.random.normal(0, 10, num_rows)\n",
        "    surface_rpm = rpm_base + (df['synthetic_rock_strength'] * rpm_strength_effect) + rpm_noise\n",
        "    df['surface_rpm'] = np.clip(surface_rpm, 50, 220)\n",
        "\n",
        "    # --- Generate Resulting Parameter (ROP) ---\n",
        "    wob_norm = (df['wt_on_bit'] - df['wt_on_bit'].mean()) / df['wt_on_bit'].std()\n",
        "    rpm_norm = (df['surface_rpm'] - df['surface_rpm'].mean()) / df['surface_rpm'].std()\n",
        "\n",
        "    rop_base = 80.0\n",
        "    rop_wob_effect = 30.0\n",
        "    rop_rpm_effect = 25.0\n",
        "    rop_strength_effect = 50.0\n",
        "    rop_noise = np.random.normal(0, 15, num_rows)\n",
        "\n",
        "    rop_average = (\n",
        "        rop_base +\n",
        "        (rop_wob_effect * wob_norm) +\n",
        "        (rop_rpm_effect * rpm_norm) -\n",
        "        (rop_strength_effect * df['synthetic_rock_strength']) +\n",
        "        rop_noise\n",
        "    )\n",
        "\n",
        "    df['rop_avg'] = np.clip(rop_average, 5, 350)\n",
        "    return df\n",
        "\n",
        "# --- Main Script ---\n",
        "print(\"--- Starting Block 2: Processing 'Expected Result' Wells ---\")\n",
        "\n",
        "# Create the new directory structure\n",
        "os.makedirs(EXPECTED_PATH, exist_ok=True)\n",
        "print(f\"Created directory: {EXPECTED_PATH}\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(INPUT_ZIP_NAME, 'r') as zip_in:\n",
        "        print(f\"Successfully opened '{INPUT_ZIP_NAME}'.\")\n",
        "\n",
        "        for file_info in zip_in.infolist():\n",
        "            file_name = file_info.filename\n",
        "\n",
        "            # Get well key: e.g., \"initial_well_logs/S1.csv\" -> \"S1\"\n",
        "            well_key = os.path.splitext(os.path.basename(file_name))[0]\n",
        "\n",
        "            # Check if it's one of our test wells\n",
        "            if (file_name.endswith('.csv') and\n",
        "                well_key in TEST_WELLS):\n",
        "\n",
        "                print(f\"  Processing EXPECTED well: {well_key}...\")\n",
        "\n",
        "                with zip_in.open(file_name) as f:\n",
        "                    df = pd.read_csv(io.TextIOWrapper(f, 'utf-8'))\n",
        "\n",
        "                df_processed = generate_synthetic_data_expected(df)\n",
        "\n",
        "                if df_processed is not None:\n",
        "                    output_file_name = f\"{well_key}_testing_expected_result.csv\"\n",
        "                    output_file_path = os.path.join(EXPECTED_PATH, output_file_name)\n",
        "                    df_processed.to_csv(output_file_path, index=False)\n",
        "                    print(f\"    -> Saved to {output_file_path}\")\n",
        "                else:\n",
        "                    print(f\"    -> Skipped {well_key} (processing error or empty).\")\n",
        "\n",
        "    print(\"\\n--- Block 2 Complete ---\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR: '{INPUT_ZIP_NAME}' not found! Please upload it. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "n2NjqweZJOe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853462fc-c337-46f9-86d0-d9d0c7dbfdf0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Block 2: Processing 'Expected Result' Wells ---\n",
            "Created directory: training_and_testing_wells/testing_wells/expected_result\n",
            "Successfully opened 'initial_well_logs.zip'.\n",
            "  Processing EXPECTED well: S2...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/expected_result/S2_testing_expected_result.csv\n",
            "  Processing EXPECTED well: S3...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/expected_result/S3_testing_expected_result.csv\n",
            "  Processing EXPECTED well: S1...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/expected_result/S1_testing_expected_result.csv\n",
            "\n",
            "--- Block 2 Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process S1, S2, S3 for \"Test Dataset\""
      ],
      "metadata": {
        "id": "8BVNimWtSPfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_ZIP_NAME = 'initial_well_logs.zip'\n",
        "OUTPUT_FOLDER_NAME = 'training_and_testing_wells'\n",
        "TEST_DATASET_PATH = os.path.join(OUTPUT_FOLDER_NAME, 'testing_wells', 'test_dataset')\n",
        "TEST_WELLS = ['S1', 'S2', 'S3'] # Wells to INCLUDE\n",
        "\n",
        "# Set a random seed for reproducible results\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Define the 'Test' processing function (GR + RHOB, NO ROP) ---\n",
        "def generate_synthetic_data_test(df):\n",
        "    num_rows = len(df)\n",
        "    if num_rows == 0: return None\n",
        "\n",
        "    # Check for required columns\n",
        "    if 'GR' not in df.columns or 'RHOB' not in df.columns:\n",
        "        print(f\"      -> ERROR: GR or RHOB missing. Cannot use this logic. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    df['GR'] = df['GR'].fillna(df['GR'].mean())\n",
        "    df['RHOB'] = df['RHOB'].fillna(df['RHOB'].mean())\n",
        "    gr_norm = (df['GR'] - df['GR'].mean()) / df['GR'].std()\n",
        "    rhob_norm = (df['RHOB'] - df['RHOB'].mean()) / df['RHOB'].std()\n",
        "    strength_proxy = rhob_norm - gr_norm\n",
        "    df['synthetic_rock_strength'] = (strength_proxy - strength_proxy.min()) / (strength_proxy.max() - strength_proxy.min())\n",
        "\n",
        "    wob_base = 20.0\n",
        "    wob_strength_effect = 30.0\n",
        "    wob_noise = np.random.normal(0, 4, num_rows)\n",
        "    wt_on_bit = wob_base + (df['synthetic_rock_strength'] * wob_strength_effect) + wob_noise\n",
        "    df['wt_on_bit'] = np.clip(wt_on_bit, 5, 70)\n",
        "\n",
        "    rpm_base = 160.0\n",
        "    rpm_strength_effect = -80.0\n",
        "    rpm_noise = np.random.normal(0, 10, num_rows)\n",
        "    surface_rpm = rpm_base + (df['synthetic_rock_strength'] * rpm_strength_effect) + rpm_noise\n",
        "    df['surface_rpm'] = np.clip(surface_rpm, 50, 220)\n",
        "\n",
        "    # --- Note: We do NOT generate rop_avg here ---\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Main Script ---\n",
        "print(\"--- Starting Block 3: Processing 'Test Dataset' Wells ---\")\n",
        "\n",
        "# Create the new directory structure\n",
        "os.makedirs(TEST_DATASET_PATH, exist_ok=True)\n",
        "print(f\"Created directory: {TEST_DATASET_PATH}\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(INPUT_ZIP_NAME, 'r') as zip_in:\n",
        "        print(f\"Successfully opened '{INPUT_ZIP_NAME}'.\")\n",
        "\n",
        "        for file_info in zip_in.infolist():\n",
        "            file_name = file_info.filename\n",
        "\n",
        "            # Get well key: e.g., \"initial_well_logs/S1.csv\" -> \"S1\"\n",
        "            well_key = os.path.splitext(os.path.basename(file_name))[0]\n",
        "\n",
        "            # Check if it's one of our test wells\n",
        "            if (file_name.endswith('.csv') and\n",
        "                well_key in TEST_WELLS):\n",
        "\n",
        "                print(f\"  Processing TEST well: {well_key}...\")\n",
        "\n",
        "                with zip_in.open(file_name) as f:\n",
        "                    df = pd.read_csv(io.TextIOWrapper(f, 'utf-8'))\n",
        "\n",
        "                df_processed = generate_synthetic_data_test(df)\n",
        "\n",
        "                if df_processed is not None:\n",
        "                    output_file_name = f\"{well_key}_usable_fortesting.csv\"\n",
        "                    output_file_path = os.path.join(TEST_DATASET_PATH, output_file_name)\n",
        "                    df_processed.to_csv(output_file_path, index=False)\n",
        "                    print(f\"    -> Saved to {output_file_path}\")\n",
        "                else:\n",
        "                    print(f\"    -> Skipped {well_key} (processing error or empty).\")\n",
        "\n",
        "    print(\"\\n--- Block 3 Complete ---\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR: '{INPUT_ZIP_NAME}' not found! Please upload it. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrF8IGyISAQ3",
        "outputId": "39ad4964-982e-4bdd-fa51-c645c094caf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Block 3: Processing 'Test Dataset' Wells ---\n",
            "Created directory: training_and_testing_wells/testing_wells/test_dataset\n",
            "Successfully opened 'initial_well_logs.zip'.\n",
            "  Processing TEST well: S2...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/test_dataset/S2_usable_fortesting.csv\n",
            "  Processing TEST well: S3...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/test_dataset/S3_usable_fortesting.csv\n",
            "  Processing TEST well: S1...\n",
            "    -> Saved to training_and_testing_wells/testing_wells/test_dataset/S1_usable_fortesting.csv\n",
            "\n",
            "--- Block 3 Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the Final Directory"
      ],
      "metadata": {
        "id": "64RytdSOSUHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "OUTPUT_FOLDER_NAME = 'training_and_testing_wells'\n",
        "OUTPUT_ZIP_NAME = 'training_and_testing_wells' # .zip is added automatically\n",
        "\n",
        "print(\"--- Starting Block 4: Zipping Final Folder ---\")\n",
        "\n",
        "try:\n",
        "    if os.path.exists(OUTPUT_FOLDER_NAME):\n",
        "        # Zip the entire output folder\n",
        "        print(f\"Zipping folder '{OUTPUT_FOLDER_NAME}'...\")\n",
        "        shutil.make_archive(\n",
        "            OUTPUT_ZIP_NAME,  # The name of the zip file to create\n",
        "            'zip',            # The format\n",
        "            OUTPUT_FOLDER_NAME # The folder to zip\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully created '{OUTPUT_ZIP_NAME}.zip'\")\n",
        "\n",
        "        # Clean up the temporary folder\n",
        "        print(f\"Cleaning up temporary folder '{OUTPUT_FOLDER_NAME}'...\")\n",
        "        shutil.rmtree(OUTPUT_FOLDER_NAME)\n",
        "\n",
        "        print(\"\\n--- Block 4 Complete ---\")\n",
        "        print(\"All tasks finished. You can now download your zip file.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"--- ERROR: Folder '{OUTPUT_FOLDER_NAME}' not found. ---\")\n",
        "        print(\"Please run Blocks 1, 2, and 3 first.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk_JKUYPST1w",
        "outputId": "ce97ce8b-080c-4cc7-e0f1-ae8a90e972aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Block 4: Zipping Final Folder ---\n",
            "Zipping folder 'training_and_testing_wells'...\n",
            "Successfully created 'training_and_testing_wells.zip'\n",
            "Cleaning up temporary folder 'training_and_testing_wells'...\n",
            "\n",
            "--- Block 4 Complete ---\n",
            "All tasks finished. You can now download your zip file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "902HMdKdStqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}